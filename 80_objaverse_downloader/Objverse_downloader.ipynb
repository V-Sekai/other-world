{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " MIT License\n",
    "\n",
    "\n",
    "\n",
    " Copyright (c) 2024-present K. S. Ernest (iFire) Lee\n",
    "\n",
    "\n",
    "\n",
    " Copyright (c) 2024 Marcus Loren\n",
    "\n",
    "\n",
    "\n",
    " Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "\n",
    " of this software and associated documentation files (the \"Software\"), to deal\n",
    "\n",
    " in the Software without restriction, including without limitation the rights\n",
    "\n",
    " to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "\n",
    " copies of the Software, and to permit persons to whom the Software is\n",
    "\n",
    " furnished to do so, subject to the following conditions:\n",
    "\n",
    "\n",
    "\n",
    " The above copyright notice and this permission notice shall be included in all\n",
    "\n",
    " copies or substantial portions of the Software.\n",
    "\n",
    "\n",
    "\n",
    " THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "\n",
    " IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "\n",
    " FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "\n",
    " AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "\n",
    " LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "\n",
    " OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "\n",
    " SOFTWARE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Install the dependencies\n",
    "\n",
    "\n",
    "\n",
    " python3 -m pip install --break-system-packages --user requests tqdm trimesh pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Step 1 - Get model sizes & path\n",
    "\n",
    "\n",
    "\n",
    " Option 1 - Extract manually:\n",
    "\n",
    " 1. Run \"git clone https://huggingface.co/datasets/allenai/objaverse\" and then abort the command when it starts to download the models.\n",
    "\n",
    " 2. This will create a git repo folder, you then can run \"python dump_gitcommits.py > out.txt\" to dump the entire commit history\n",
    "\n",
    " 3. Then you call extract_models_from_dump(\"out.txt\") to parse and get all the model paths and their sizes.\n",
    "\n",
    "\n",
    "\n",
    " Option 2 - Use the pre-extracted json (model_sizes.json.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798759\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import json \n",
    "import gzip\n",
    "\n",
    "def extract_models_from_dump(file_path):\n",
    "    model_sizes = {}\n",
    "    current_model = None\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Get model path\n",
    "            if \".glb\" in line:\n",
    "                # Extract model path\n",
    "                model_path = line.split()[-1].strip()\n",
    "                model_path = model_path.replace(\"b/\", \"\")\n",
    "                current_model = model_path\n",
    "            # Get current_model size\n",
    "            elif current_model and \"size\" in line: \n",
    "                \n",
    "                size = int(line.split()[-1].strip()) \n",
    "                model_sizes[current_model] = size \n",
    "                current_model = None\n",
    "    return model_sizes\n",
    " \n",
    " \n",
    " ## Option 1\n",
    "#model_sizes = extract_models_from_dump(\"out.txt\")  \n",
    "\n",
    "\n",
    "## Option 2\n",
    "with gzip.open(\"model_sizes.json.gz\", 'rb') as gzip_file: \n",
    "    model_sizes = json.loads(gzip_file.read().decode('utf-8'))\n",
    "    \n",
    "print(len(model_sizes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Download the meshes as per specified size limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm  \n",
    "from concurrent.futures import ThreadPoolExecutor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Download metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-001.json.gz?download=truehttps://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-002.json.gz?download=true\n",
      "\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-003.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-004.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-005.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-006.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 7/160 [00:00<00:06, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-007.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-008.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-009.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-010.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-011.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-012.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-013.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-014.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-015.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-016.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-017.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 13/160 [00:00<00:05, 26.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-018.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-019.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-020.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-021.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-022.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-023.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-024.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 23/160 [00:00<00:04, 30.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-025.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-026.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-027.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-028.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-029.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-030.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-031.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-032.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-033.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 27/160 [00:00<00:04, 30.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-034.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-035.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-036.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-037.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-038.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-039.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-040.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 39/160 [00:01<00:03, 33.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-041.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-042.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-043.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-044.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-045.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-046.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-047.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-048.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 46/160 [00:01<00:03, 37.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-049.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-050.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-051.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-052.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-053.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-054.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-055.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-056.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-057.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 52/160 [00:01<00:03, 30.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-058.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-059.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-060.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-061.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-062.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-063.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-064.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 58/160 [00:01<00:03, 29.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-065.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-066.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-067.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-068.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-069.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-070.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-071.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-072.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 73/160 [00:02<00:02, 41.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-073.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-074.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-075.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-076.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-077.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-078.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-079.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 78/160 [00:02<00:02, 38.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-080.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-081.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-082.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-083.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-084.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-085.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-086.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 87/160 [00:02<00:01, 36.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-087.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-088.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-089.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-090.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-091.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-092.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-093.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-094.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-095.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-096.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 97/160 [00:02<00:01, 38.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-097.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-098.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-099.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-100.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-101.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-102.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-103.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-104.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 101/160 [00:03<00:01, 29.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-105.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-106.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-107.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-108.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-109.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-110.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-111.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-112.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-113.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-114.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-115.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-116.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-117.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 106/160 [00:03<00:02, 19.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-118.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-119.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-120.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-121.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-122.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-123.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-124.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-125.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 123/160 [00:03<00:00, 39.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-126.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-127.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-128.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-129.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-130.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-131.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-132.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 129/160 [00:03<00:00, 34.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-133.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-134.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-135.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-136.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-137.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-138.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-139.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-140.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 135/160 [00:04<00:00, 37.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-141.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-142.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-143.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-144.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-145.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-146.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-147.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-148.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-149.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-150.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-151.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-152.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-153.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-154.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-155.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-156.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-157.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-158.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-159.json.gz?download=true\n",
      "https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-160.json.gz?download=true\n",
      "Failed to download 000-160.json.gz. Error: 404 Client Error: Not Found for url: https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/000-160.json.gz?download=true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:05<00:00, 30.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import os\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, folder_path, filename):\n",
    "    url = url + \"?download=true\"\n",
    "    print(url)\n",
    "    try:\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()  # If the response was successful, no Exception will be raised\n",
    "        with open(os.path.join(folder_path, filename), 'wb') as f:\n",
    "            f.write(response.content) \n",
    "        return True\n",
    "    except Exception as err:\n",
    "        print(f\"Failed to download {filename}. Error: {err}\")\n",
    "        return False\n",
    "\n",
    "def download_metadata(base_url, save_dir, num_threads=6):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for i in range(1, 161):\n",
    "            filename = f\"000-{i:03d}.json.gz\"\n",
    "            file_url = base_url + filename\n",
    "            futures.append(executor.submit(download_file, file_url, save_dir, filename))\n",
    "\n",
    "        for future in tqdm(futures, total=len(futures)):\n",
    "            result = future.result()\n",
    "            if not result:\n",
    "                continue\n",
    "            \n",
    "base_url = \"https://huggingface.co/datasets/allenai/objaverse/resolve/main/metadata/\" \n",
    "save_dir = './objaverse/metadata'\n",
    "os.makedirs(save_dir, exist_ok=True)   \n",
    "\n",
    "download_metadata(base_url, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Extract the metadata to a JSON with only the relevant information, e.g the models you downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from pygltflib import GLTF2, BufferFormat\n",
    "from tqdm import tqdm\n",
    "\n",
    "captions_df = pd.read_csv('./objaverse_annotations/pali_captions.csv', sep=';')\n",
    "material_annotations_df = pd.read_csv('./objaverse_annotations/pali_material_annotations.csv', sep=';')\n",
    "type_annotations_df = pd.read_csv('./objaverse_annotations/pali_type_annotations.csv', sep=';')\n",
    "captions_dict = captions_df.set_index('object_uid').T.to_dict('list')\n",
    "material_annotations_dict = material_annotations_df.set_index('object_uid').T.to_dict('list')\n",
    "type_annotations_dict = type_annotations_df.set_index('object_uid').T.to_dict('list')\n",
    "\n",
    "existing_models = {}\n",
    "metadata = {}\n",
    "filtered_metadata = {}\n",
    "metadata_path = './objaverse/metadata'\n",
    "for file_name in os.listdir(metadata_path):\n",
    "    if file_name.endswith(\".gz\"):\n",
    "        file_path = os.path.join(metadata_path, file_name)\n",
    "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "            file_metadata = json.load(f)\n",
    "            metadata.update(file_metadata)\n",
    "\n",
    "input_directory = './objaverse/glbs'\n",
    "output_gltf_directory = './objaverse/gltf_xmp_json_ld'\n",
    "scaling_factor_constant = 0.95\n",
    "\n",
    "os.makedirs(output_gltf_directory, exist_ok=True)\n",
    "\n",
    "def convert_lists_to_ordered_xmp_format(data):\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, list):\n",
    "            # Always use '@list' to represent an ordered list.\n",
    "            data[key] = {'@list': value}\n",
    "        elif isinstance(value, dict):\n",
    "            convert_lists_to_ordered_xmp_format(value)\n",
    "\n",
    "def add_to_filtered_metadata(key, value):\n",
    "    if value is not None:\n",
    "        filtered_metadata[f\"vsekai:{key}\"] = value\n",
    "\n",
    "def download_model_convert_and_delete(model_url, glb_path, gltf_path):\n",
    "    try:\n",
    "        response = requests.get(model_url)\n",
    "        if response.status_code == 200:\n",
    "            # Save the GLB file temporarily\n",
    "            with open(glb_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # Convert the GLB file to GLTF format with XMP metadata\n",
    "            gltf = GLTF2().load(glb_path)\n",
    "            gltf.convert_buffers(BufferFormat.DATAURI)\n",
    "            if not os.path.isfile(file_path):\n",
    "                return\n",
    "            start_time = time.time()\n",
    "            file_name, file_extension = os.path.splitext(file_path)\n",
    "            existing_models[os.path.basename(file_name)] = file_path\n",
    "            if not file_extension.lower() == \".glb\" and os.path.basename(file_name) in metadata:\n",
    "                return\n",
    "            gltf_file_path = os.path.join(output_gltf_directory, os.path.basename(file_name) + \".gltf\")\n",
    "            if os.path.exists(gltf_file_path):\n",
    "                return\n",
    "            gltf = GLTF2().load(file_path)\n",
    "            gltf.convert_buffers(BufferFormat.DATAURI)\n",
    "            gltf.save(gltf_file_path)\n",
    "            data = metadata[os.path.basename(file_name)]\n",
    "            if data[\"license\"] != \"by\":\n",
    "                os.remove(gltf_file_path)\n",
    "                return\n",
    "            \n",
    "            if not (100 <= data[\"faceCount\"] <= 2000):\n",
    "                os.remove(gltf_file_path)\n",
    "                return\n",
    "                \n",
    "            convert_lists_to_ordered_xmp_format(data)\n",
    "            filtered_metadata = {\n",
    "                \"@context\": {\n",
    "                    \"dc\": \"http://purl.org/dc/elements/1.1/\",\n",
    "                    \"vsekai\": \"http://v-sekai.org/vsekai/elements/0.4/\"\n",
    "                },\n",
    "                \"@id\": data[\"uid\"],\n",
    "                \"dc:title\": data[\"name\"],\n",
    "                \"dc:creator\": {\n",
    "                    \"@id\": data[\"user\"][\"uid\"],\n",
    "                    \"dc:name\": data[\"user\"][\"username\"]\n",
    "                },\n",
    "                \"dc:description\": data[\"description\"],\n",
    "                \"dc:date\": data[\"createdAt\"],\n",
    "                \"dc:identifier\": data[\"uri\"],\n",
    "                \"dc:source\": data[\"viewerUrl\"],\n",
    "                \"dc:rights\": data[\"license\"],\n",
    "                \"dc:subject\": data[\"tags\"],\n",
    "                \"dc:type\": \"3D Model\",\n",
    "                \"dc:relation\": data[\"user\"][\"profileUrl\"],\n",
    "                \"vsekai:viewCount\": data[\"viewCount\"],\n",
    "                \"vsekai:likeCount\": data[\"likeCount\"],\n",
    "                \"vsekai:commentCount\": data[\"commentCount\"],\n",
    "                \"vsekai:isDownloadable\": data[\"isDownloadable\"],\n",
    "                \"vsekai:publishedAt\": data[\"publishedAt\"],\n",
    "                \"vsekai:faceCount\": data[\"faceCount\"],\n",
    "                \"vsekai:vertexCount\": data[\"vertexCount\"],\n",
    "                \"vsekai:isAgeRestricted\": data[\"isAgeRestricted\"],\n",
    "            }\n",
    "\n",
    "            if data[\"uid\"] in captions_dict:\n",
    "                caption_annotation, caption_annotation_probability = captions_dict[data[\"uid\"]]\n",
    "                add_to_filtered_metadata(\"captionAnnotation\", caption_annotation)\n",
    "                add_to_filtered_metadata(\"captionAnnotationProbability\", caption_annotation_probability)\n",
    "\n",
    "            if data[\"uid\"] in material_annotations_dict:\n",
    "                material_annotation, material_annotation_probability = material_annotations_dict[data[\"uid\"]]\n",
    "                add_to_filtered_metadata(\"materialAnnotation\", material_annotation)\n",
    "                add_to_filtered_metadata(\"materialAnnotationProbability\", material_annotation_probability)\n",
    "\n",
    "            if data[\"uid\"] in type_annotations_dict:\n",
    "                type_annotation, type_annotation_probability = type_annotations_dict[data[\"uid\"]]\n",
    "                add_to_filtered_metadata(\"typeAnnotation\", type_annotation)\n",
    "                add_to_filtered_metadata(\"typeAnnotationProbability\", type_annotation_probability)\n",
    "\n",
    "            optional_tags = [\"animationCount\", \"staffpickedAt\", \"archives\", \"categories\"]\n",
    "            for tag in optional_tags:\n",
    "                if tag in data:\n",
    "                    add_to_filtered_metadata(tag, data[tag])\n",
    "\n",
    "            with open(gltf_file_path, 'r') as f:\n",
    "                gltf_json = json.load(f)\n",
    "\n",
    "            xmp_extension = {\n",
    "                \"KHR_xmp_json_ld\": {\n",
    "                    \"packets\": [filtered_metadata]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            if 'extensions' in gltf_json['asset']:\n",
    "                if 'KHR_xmp_json_ld' in gltf_json['asset']['extensions']:\n",
    "                    gltf_json['asset']['extensions']['KHR_xmp_json_ld']['packets'].append(filtered_metadata)\n",
    "                else:\n",
    "                    gltf_json['asset']['extensions'].update(xmp_extension)\n",
    "            else:\n",
    "                gltf_json['asset']['extensions'] = xmp_extension\n",
    "\n",
    "            gltf_json['asset']['extensions']['KHR_xmp_json_ld']['packet'] = len(gltf_json['asset']['extensions']['KHR_xmp_json_ld']['packets']) - 1\n",
    "\n",
    "            if 'extensionsUsed' in gltf_json:\n",
    "                if \"KHR_xmp_json_ld\" not in gltf_json['extensionsUsed']:\n",
    "                    gltf_json['extensionsUsed'].append(\"KHR_xmp_json_ld\")\n",
    "            else:\n",
    "                gltf_json['extensionsUsed'] = [\"KHR_xmp_json_ld\"]\n",
    "\n",
    "            with open(gltf_file_path, 'w') as f:\n",
    "                json.dump(gltf_json, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "            # Save the converted GLTF file\n",
    "            gltf.save(gltf_path)\n",
    "\n",
    "            # Delete the GLB file\n",
    "            os.remove(glb_path)\n",
    "        else:\n",
    "            print(f\"Failed to download: {model_url}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading: {model_url}, {e}\")\n",
    "\n",
    "def download_filtered_models(model_sizes, filtered_json, base_url, save_dir, minKb, maxKb, num_threads = 6, maxDownloadedMeshes = 1):\n",
    "    filtered_models = {model_path: size for model_path, size in model_sizes.items() if minKb < size < maxKb * 1024}\n",
    "\n",
    "    downloaded_meshes = 0\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = []\n",
    "        for model_path, size in filtered_models.items():\n",
    "            if downloaded_meshes >= maxDownloadedMeshes:\n",
    "                break\n",
    "\n",
    "            if model_path in filtered_json:\n",
    "                continue\n",
    "            \n",
    "            folder_name = os.path.dirname(model_path)\n",
    "            sub_folder = os.path.join(save_dir, folder_name)\n",
    "            os.makedirs(sub_folder, exist_ok=True)\n",
    "            \n",
    "            file_name = os.path.basename(model_path)\n",
    "            save_path = os.path.join(sub_folder, file_name)\n",
    "\n",
    "            if file_name in model_sizes:\n",
    "                print(\"The file is filtered from this dataset.\")\n",
    "                continue\n",
    "            \n",
    "            if not os.path.exists(save_path):\n",
    "                model_url = f\"{base_url}/{model_path}?download=true\"\n",
    "                base_save_path, _ = os.path.splitext(save_path)\n",
    "                glb_path = base_save_path + '.glb'                \n",
    "                futures.append(executor.submit(download_model_convert_and_delete, model_url, glb_path, save_path))\n",
    "                \n",
    "                downloaded_meshes += 1\n",
    "                \n",
    "        for future in tqdm(futures, total=len(futures)):\n",
    "            future.result()\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/allenai/objaverse/resolve/main\"  \n",
    "save_dir = f'./objaverse' \n",
    "\n",
    "json_file_path = \"filtered_face_count.json\"\n",
    "filtered_json = {}\n",
    "\n",
    "if os.path.exists(json_file_path):\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        filtered_json = json.load(f)\n",
    "else:\n",
    "    print(f'File {json_file_path} does not exist.')\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/003e2f4de1fb4d3fadc18655a5d8966e.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/0020199e55034ddba35a8daf4670253b.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/005a8f2d0e734c338445d93ed4b8f53f.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/001df836dd9e46edb196a975e59bb63a.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/007b95d23a834fb5bad6a09daf27126d.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/005a246f8c304e77b27cf11cd53ff4ed.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/00429580c6634d70a4164203d28f2735.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n",
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/00600cf173c14c9b94f1499014e5771b.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:00<00:06,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/0017dc02a1e74e029ecf929fd9d94172.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:18<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error downloading: https://huggingface.co/datasets/allenai/objaverse/resolve/main/glbs/000-159/007a654b3ac742bc8fa3073fb055ccb2.glb?download=true, 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "download_filtered_models(model_sizes, filtered_json, base_url, save_dir, minKb = 301, maxKb = 40960, num_threads = 24, maxDownloadedMeshes = 300000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
